---
layout: post
title: "TensorFlow - 基于 AlexNet 图像分类"
date: 2018-01-20 
tag: 卷积神经网络  

---


### 基本理论

![](/images/posts/alexnet/alexnet_1.png)
<h5 align = "center">图 1.1</h5>

AlexNet是具有历史意义的一个网络结构，在此之前，深度学习已经沉寂了很久。2012 年，AlexNet在当年的ImageNet图像分类竞赛中，top-5错误率比上一年的冠军下降了十个百分点，而且远远超过当年的第二名。网络结构如图1.1所示，包含五层卷积层和三层全连接层，总共包含约6000万个参数。下面详细介绍AlexNet网络：

#### ReLU

![](/images/posts/alexnet/alexnet_2.png)
<h5 align = "center">图 1.2</h5>

$$
\begin{aligned}
f(x)=max(0,z)
\end{aligned}
$$

优点：
* 在输入大于 0 时候，不会出现梯度消失；
* 相较于 sigmoid 和 tanh 收敛速度大大提升，不含有 exp 运算，计算速度提升。

缺点：
* 输出不是关于中心点对称；
* 当输入小于 0，在前向传播时 ReLU 一直处于非激活状态，那么反向传播就会出现梯度消失(未激活的神经元局部梯度为 0 )，因此非激活的神经元无法进行反向传播，它的权重也不会更新；当输入大于 0 ，ReLU 神经元直接将梯度传给前面层网络；当输入为 0，梯度未定义，我们可以简单指定为 0 或 1（实际出现输入为 0 的概率很小）；
* 可能出现 ReLU 神经元失活问题，如 $max(0,w^{T}x+b)$ ，假设 $w、b$ 都初始化为 0，或者更新过程中，$w、b$ 更新为一种特别状态，使得 永远小于 0，那么该神经元权重将永远得不到更新。

#### Data Augmentation

神经网络是靠数据喂出来的，同时扩大数据集合可以有效地解决过拟合问题，可以通过一些简单的变换从已有的训练数据集中生成一些新的数据，来扩充训练数据集。

* `镜像对称（Mirroring）`

![](/images/posts/alexnet/alexnet_3.png)
<h5 align = "center">图 1.3</h5>

* `随机裁剪（Random Cropping）`

![](/images/posts/alexnet/alexnet_4.png)
<h5 align = "center">图 1.4</h5>

* `色彩变换（Color shifting）`

在实践中增加的 RGB 值是根据某种概率分布来决定的。PCA 颜色增强，其含义是：比如图像呈现紫色，即主要含有红色和蓝色，绿色很少，那么 PCA 颜色增强就会对红色和蓝色增减很多，绿色变化相对少一点，所以使总体的颜色保持一致。
![](/images/posts/alexnet/alexnet_5.png)
<h5 align = "center">图 1.5</h5>

AlexNet Data Augmentation 做法是：
* `Random Cropping`：从 $256\times256$ 的图像中随机裁剪 $224\times224$（包括 Mirroring 图像），相当于将样本增加 $(256-224)^{2}\times2=2048$；
* `Color shifting`：采用 PCA 方法处理整个 ImageNet 数据集合，将每个素的 RGB 值 $\left[ I^{R}\_{xy},I^{G}\_{xy},I^{B}\_{xy}\right]^{T}$ 加上 $\left[p\_{1},p\_{2},p\_{3}\right]\left[ \alpha\_{1}\lambda\_{1},\alpha\_{2}\lambda\_{2},\alpha\_{3}\lambda\_{3}\right]^{T}$ 其中 $p\_{i}$ 和 $\lambda\_{i}$ 分别是 RGB 值的 $3 \times 3$ 协方差矩阵的第 $i$ 个特征向量和特征值。$\alpha\_{i}$ 是一个服从均值为 $0$，标准差为 $1$ 的高斯分布的高斯变量。简单说明下怎么求解协方差矩阵的，假设训练集有  $m$ 张图片，每张图片大小为 $w \times h$，我们将 $m$ 图片转化为 $X \in R^{\left(m \times w \times h,3\right)}$ 的二维向量，三列分别表示  RGB 三个通道灰度值，对这个二维矩阵求协方差矩阵，可以得到 $3 \times 3$ 的 RGB 协方差矩阵 $C$，协方差具体求法如下公式(1.1)，其中 $x\_{i}$ 表示第 $i$ 列的向量， $x\_{j}$ 表示第 $j$ 列的向量。

$$
\left[ \begin{matrix}
  cov(x_{1},x_{1}) & cov(x_{1},x_{2}) & cov(x_{1},x_{3}) \\
  cov(x_{2},x_{1}) & cov(x_{2},x_{2}) & cov(x_{2},x_{3}) \\
  cov(x_{3},x_{1}) & cov(x_{3},x_{2}) & cov(x_{3},x_{3})
\end{matrix} \right] \tag{1.1} \\
$$
其中 $cov(x\_{i},x\_{j}) = E\left[\left( x\_{i} - E\left[ x\_{i}\right] \right) \left( x\_{j} - E\left[ x\_{j}\right] \right)^{T} \right]$

#### Dropout

![](/images/posts/alexnet/alexnet_7.png)
<h5 align = "center">图1.6</h5>
如图1.6所示，对第 $i$ 层进行 Dropout，保留某个神经元的概率为 keep_prob 。前向传播的时候让某个神经元的激活值以一定概率 1 - keep_prob 停止工作（即把该神经元的激活值设为0），为了不影响整个网络输出的期望值，未被Dropout的神经元的激活值除以 keep_prob，具体见算法1.1：
```
Train:
    d[i] = np.random.rand(a[i].shape[0],a[i].shape[1]) < keep_prob
    a[i] = np.multiple(a[i],d[i])
    a[i] /= keep_prob
    z[i+1] = w[i+1]a[i]+b[i+1]
Test:
    Do Nothing

```
为什么需要除以 keep_prob？假设 $l$ 层有 $50$ 个 uinits，keep_prob = 0.8，大概有 $10$ 个 uinits 被置 $0$，$z^\left[ l+1 \right] = w^\left[ l+1 \right] a^\left[ l \right] + b^\left[ l \right]$，$a^{\left[ l \right]}$ 的期望相比 Dropout 之前减少 $20%$，为了不影响 $z^{\left[ l+1 \right]}$ 的期望，$a^{\left[ l \right]}$ 需要除以 $0.8$ 用来修正或弥补 Dropout 掉的 $20%$。目的是确保即使在测试阶段不执行 Dropout 来调整数值范围，激活函数的预测结果也不会发生变化。（测试阶段不进行Dropout，因为如果在测试阶段应用Dropout，每次Dropout的神经元都是变化的，预测会受到干扰。）
为什么Dropout可以起到正则化作用？由前面可知正则化的本质是减少网络对某些神经元过分依赖。直观地认识，训练一个网络，每次迭代过程中，任何一个神经元都有可能被Dropout，所以后一层的神经元输入不会过分依赖前一层的任何一个神经元的输出，不会给前一层任何一个神经元太多权重，而是尽可能的均分到每个神经元上。和前面介绍的L2范数有异曲同工之妙。Cannot rely on any one feature,so have to spread out weights。

#### 局部归一化
$$
\begin{aligned}
b^{i}_{x,y} = a^{i}_{x,y}/\left(k+\alpha\sum^{min\left(N-1,i+n/2\right)}_{j=max\left(0,i-n/2\right)}\left(a^{j}_{x,y}\right)^{2}\right)^{\beta} \tag{1.2}
\end{aligned}
$$

其中 $a^{i}\_{x,y}$ 表示第 $i$ 个卷积核在 $(x,y)$ 位置产生的值再应用 ReLU 激活函数后的结果，$n$ 表示相邻的几个卷积核，$N$ 表示这一层总的卷积核数量，$k=2,n=5,\alpha=0.0001,\beta=0.75$ 是超参数。如图 1.7 所示，选取一个位置，在第三维度上穿过，图中白色区域，可以得到10个相邻的元素，然后利用公式(1.2)进行归一化。后面研究发现LRN作用不大，所以后面看到的网络一般不采用LRN。
![](/images/posts/alexnet/alexnet_11.png)
<h5 align = "center">图1.7</h5>

### 网络结构分析

![](/images/posts/alexnet/alexnet_6.png)
<h5 align = "center">图1.8</h5>

##### 第一层 卷积层

* `conv`：输入的 shape 为 $227\times227\times3$，$96$ 个 $11\times11$ 的卷积核，步长为 $s=4$，$Valid$ 方式。输出的 shape 为 $55\times55\times96$，其中$\left\lfloor\frac{227-11}{4}+1\right\rfloor=55$ 。
* `lrn`：对卷积结果进行局部归一化。
* `max-pool`：输入的 shape 为 $55\times55\times96$，池化参数 $f=3,s=2$，$Valid$ 方式，输出的 shape 为 $27\times27\times96$，其中$\left\lfloor\frac{55-3}{2}+1\right\rfloor=27$

##### 第二层 卷积层

* `conv`：输入 $27\times27\times96$，卷积参数 $5\times5\times256$ 卷积核，步长为 $strides=1$，$Same$ 方式。输出 $27\times27\times256$，其中 $padding：\frac{5-1}{2}=2$，$\left\lfloor\frac{27+2\times2-5}{1}+1\right\rfloor=27$。
* `lrn`：对卷积结果进行局部归一化。
* `max-pool`：输入 $27\times27\times256$，池化参数 $z=3,s=2$，$Valid$ 方式，输出 $13\times13\times256$，其中$\left\lfloor\frac{27-3}{2}+1\right\rfloor=13$

##### 第三层 卷积层

* `conv`：输入 $13\times13\times256$，卷积参数 $3\times3\times384$ 卷积核，步长为 $strides=1$，$Same$ 方式。输出 $13\times13\times384$，其中 $padding：\frac{3-1}{2}=1$，$\left\lfloor\frac{13+2\times1-3}{1}+1\right\rfloor=13$。

##### 第四层 卷积层

* `conv`：输入 $13\times13\times384$，卷积参数 $3\times3\times384$ 卷积核，步长为 $strides=1$，$Same$ 方式。输出 $13\times13\times384$，其中 $padding：\frac{3-1}{2}=1$，$\left\lfloor\frac{13+2\times1-3}{1}+1\right\rfloor=13$。

##### 第五层 卷积层

* `conv`：输入 $13\times13\times384$，卷积参数 $3\times3\times256$ 卷积核，步长为 $strides=1$，$Same$ 方式。输出 $13\times13\times256$，其中 $padding：\frac{3-1}{2}=1$，$\left\lfloor\frac{13+2\times1-3}{1}+1\right\rfloor=13$。
* `max-pool`：输入  $13\times13\times256$，池化参数 $z=3,s=2$，$Valid$ 方式，输出 $6\times6\times256$，其中$\left\lfloor\frac{13-3}{2}+1\right\rfloor=6$

##### 第六层 全连接层
* `fc`：$6\times6\times256\rightarrow4096$。
* `Dropout`：0.5。

##### 第七层 全连接层
* `fc`：$4096\rightarrow4096$。
* `Dropout`：0.5。

##### 第八层 全连接层
* `fc`：$4096\rightarrow1000$。

### 代码分析
[github](https://github.com/learning17/machinelearning/tree/master/alexnet)

#### 代码结构
* `generate_alexnet.py`：训练数据；
* `alexnet.py`：AlexNet 模型；
* `train_alexnet.py`：训练 AlexNet 模型；
* `predict_alexnet.py`：验证 AlexNet 模型。

#### 训练数据

采用  [Kaggle Dogs vs. Cats Redux Competition](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data) 作为训练数据，训练猫、狗二分类器。把train.zip数据分为训练集和验证集 (70/30) ，并分别保存在 `train.txt` 和 `val.txt`。格式为：filename  label，0：Dogs，1：Dogs。`get_image_path_label` 实现该功能。 
```
data/train/dog.7412.jpg 1                               
data/train/cat.1290.jpg 0
```
#### AlexNet 模型

* 1st layer: conv -> lrn -> pool
* 2nd layer: conv -> lrn -> pool (split into 2 groups)
* 3rd layer: conv
* 4th layer: conv (split into 2 groups)
* 5th layer: conv -> pool (split into 2 groups)
* 6th layer: fully-connected -> dropout
* 7th layer: fully-connected -> dropout
* 8th layer: fully-connected

![](/images/posts/alexnet/alexnet_10.png)

#### 训练 AlexNet 模型

本次实验没有从头开始完全训练整个网络，前面五层的卷积层直接采用已训练好的[参数](http://www.cs.toronto.edu/~guerzhoy/tf_alexnet/) ，我们训练后面三层的全连接层。
在验证集上的准确度为 $0.966$ 。
![](/images/posts/alexnet/alexnet_8.png)
![](/images/posts/alexnet/alexnet_9.png)

#### 验证 AlexNet 模型

主要实现两个功能：
* ImageNet 图像分类，取概率最大的五类；
* Dogs vs. Cats 分类。
